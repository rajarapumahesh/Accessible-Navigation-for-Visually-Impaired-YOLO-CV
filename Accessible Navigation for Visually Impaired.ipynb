{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4224a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the image file\n",
    "image_path = r\"C:\\Users\\MAHESH\\Pictures\\ATIFR 2022\\243.jpeg\"\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "else:\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on original image\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display results\n",
    "    cv2.imshow('Detected Obstacles', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95122558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstacle detected. Please navigate around it.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to detect obstacles and provide navigation feedback\n",
    "def detect_obstacles_and_navigate(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on original image\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Check for obstacles\n",
    "    if len(contours) > 0:\n",
    "        # If obstacles are detected, provide feedback to user\n",
    "        print(\"Obstacle detected. Please navigate around it.\")\n",
    "        # Add code here to provide auditory feedback to the user (e.g., using speech synthesis)\n",
    "\n",
    "    else:\n",
    "        # If no obstacles are detected, provide navigation instructions\n",
    "        print(\"No obstacles detected. Proceed straight ahead.\")\n",
    "        # Add code here to provide auditory feedback to the user (e.g., using speech synthesis)\n",
    "\n",
    "    # Display results\n",
    "    cv2.imshow('Detected Obstacles', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load image\n",
    "image_path = r\"C:\\Users\\MAHESH\\Pictures\\Camera Roll\\2.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "else:\n",
    "    # Detect obstacles and provide navigation feedback\n",
    "    detect_obstacles_and_navigate(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ea4fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 1: person (Confidence: 0.62)\n",
      "Object 1: person (Confidence: 0.70)\n",
      "Object 1: motorbike (Confidence: 0.51)\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names and their corresponding confidences\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    object_names = []\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name\n",
    "                object_name = classes[class_id]\n",
    "                object_names.append(object_name)\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Display object names and their confidences\n",
    "    for i, object_name in enumerate(object_names):\n",
    "        print(f\"Object {i+1}: {object_name} (Confidence: {confidences[i]:.2f})\")\n",
    "\n",
    "    # Display results on the frame\n",
    "    for i in range(len(object_names)):\n",
    "        cv2.putText(frame, object_names[i], (50, 50 + 30*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Videos\\VID20220428102215.mp4\"   # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Perform object detection on the frame\n",
    "        detected_frame = detect_objects(frame)\n",
    "\n",
    "        # Display the detected frame\n",
    "        cv2.imshow('Object Detection', detected_frame)\n",
    "\n",
    "        # Check for key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release video capture device and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06db5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: comtypes in c:\\users\\mahesh\\ansel\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\mahesh\\ansel\\lib\\site-packages (from pyttsx3) (302)\n",
      "Installing collected packages: pypiwin32, pyttsx3\n",
      "Successfully installed pypiwin32-223 pyttsx3-2.90\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e267a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    person_detected = False\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names, positions, and confidences\n",
    "    object_names = []\n",
    "    object_positions = []\n",
    "    confidences = []\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name and position\n",
    "                object_name = classes[class_id]\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                object_names.append(object_name)\n",
    "                object_positions.append((center_x, center_y))\n",
    "                confidences.append(float(confidence))\n",
    "                if object_name == 'person':\n",
    "                    person_detected = True\n",
    "\n",
    "    # Perform distance calculation if a person is detected\n",
    "    if person_detected:\n",
    "        for i, object_name in enumerate(object_names):\n",
    "            if object_name != 'person':\n",
    "                person_x, person_y = object_positions[0]\n",
    "                object_x, object_y = object_positions[i]\n",
    "                distance = calculate_distance(person_x, person_y, object_x, object_y)\n",
    "\n",
    "                # Display information\n",
    "                info_text = f\"{object_name} is {'right' if object_x > person_x else 'left'} of you, {int(distance)} feet away\"\n",
    "                print(info_text)\n",
    "\n",
    "                # Convert information to speech\n",
    "                engine.say(info_text)\n",
    "                engine.runAndWait()\n",
    "\n",
    "    # Display results on the frame\n",
    "    for i in range(len(object_names)):\n",
    "        cv2.putText(frame, object_names[i], object_positions[i], cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Busy people walking the city streets in London, HD Stock Footage.mp4\" # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame\n",
    "        detected_frame = detect_objects(frame)\n",
    "\n",
    "        # Display the detected frame\n",
    "        cv2.imshow('Object Detection', detected_frame)\n",
    "\n",
    "        # Check for key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release video capture device and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d7c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck is 315 feet away, left of you\n",
      "person is 650 feet away, right of you\n",
      "traffic light is 621 feet away, left of you\n",
      "bus is 487 feet away, right of you\n",
      "backpack is 350 feet away, right of you\n",
      "handbag is 596 feet away, right of you\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# Function to determine direction based on object position\n",
    "def determine_direction(person_x, person_y, object_x, object_y):\n",
    "    if object_x > person_x + 50:\n",
    "        return \"right\"\n",
    "    elif object_x < person_x - 50:\n",
    "        return \"left\"\n",
    "    elif object_y < person_y:\n",
    "        return \"front\"\n",
    "    elif object_y > person_y:\n",
    "        return \"behind\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names, positions, and confidences\n",
    "    object_names = []\n",
    "    object_positions = []\n",
    "    confidences = []\n",
    "\n",
    "    # Detect person's position (assumed to be in the center)\n",
    "    person_x, person_y = width // 2, height // 2\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name and position\n",
    "                object_name = classes[class_id]\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                object_names.append(object_name)\n",
    "                object_positions.append((center_x, center_y))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Keep track of detected objects to avoid duplicates\n",
    "    detected_objects = set()\n",
    "\n",
    "    # Iterate through detected objects\n",
    "    for object_name, object_position in zip(object_names, object_positions):\n",
    "        # Check if object has already been detected\n",
    "        if object_name not in detected_objects:\n",
    "            # Calculate distance and direction\n",
    "            object_x, object_y = object_position\n",
    "            distance = calculate_distance(person_x, person_y, object_x, object_y)\n",
    "            direction = determine_direction(person_x, person_y, object_x, object_y)\n",
    "\n",
    "            # Display information\n",
    "            info_text = f\"{object_name} is {int(distance)} feet away, {direction} of you\"\n",
    "            print(info_text)\n",
    "\n",
    "            # Convert information to speech\n",
    "            engine.say(info_text)\n",
    "            engine.runAndWait()\n",
    "\n",
    "            # Add object to detected set\n",
    "            detected_objects.add(object_name)\n",
    "\n",
    "    # Exit after processing all detected objects\n",
    "    return True\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Busy people walking the city streets in London, HD Stock Footage.mp4\"  # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame\n",
    "        if detect_objects(frame):\n",
    "            # Exit after detecting all objects\n",
    "            break\n",
    "\n",
    "# Release video capture device\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d81345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# Function to determine direction based on object position\n",
    "def determine_direction(person_x, person_y, object_x, object_y):\n",
    "    if object_x > person_x + 50:\n",
    "        return \"right\"\n",
    "    elif object_x < person_x - 50:\n",
    "        return \"left\"\n",
    "    elif object_y < person_y:\n",
    "        return \"front\"\n",
    "    elif object_y > person_y:\n",
    "        return \"behind\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame, max_distance):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names, positions, and confidences\n",
    "    object_names = []\n",
    "    object_positions = []\n",
    "    confidences = []\n",
    "\n",
    "    # Detect person's position (assumed to be in the center)\n",
    "    person_x, person_y = width // 2, height // 2\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name and position\n",
    "                object_name = classes[class_id]\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                object_names.append(object_name)\n",
    "                object_positions.append((center_x, center_y))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Keep track of detected objects to avoid duplicates\n",
    "    detected_objects = set()\n",
    "\n",
    "    # Iterate through detected objects\n",
    "    for object_name, object_position in zip(object_names, object_positions):\n",
    "        # Check if object has already been detected\n",
    "        if object_name not in detected_objects:\n",
    "            # Calculate distance and direction\n",
    "            object_x, object_y = object_position\n",
    "            distance = calculate_distance(person_x, person_y, object_x, object_y)\n",
    "            direction = determine_direction(person_x, person_y, object_x, object_y)\n",
    "\n",
    "            # Check if object is within max distance\n",
    "            if distance <= max_distance:\n",
    "                # Display information\n",
    "                info_text = f\"{object_name} is {int(distance)} feet away, {direction} of you\"\n",
    "                print(info_text)\n",
    "\n",
    "                # Convert information to speech\n",
    "                engine.say(info_text)\n",
    "                engine.runAndWait()\n",
    "\n",
    "                # Add object to detected set\n",
    "                detected_objects.add(object_name)\n",
    "\n",
    "    # Exit after processing all detected objects\n",
    "    return True\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Busy people walking the city streets in London, HD Stock Footage.mp4\"  # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame with max distance of 10 feet\n",
    "        if detect_objects(frame, max_distance=10):\n",
    "            # Display the frame\n",
    "            cv2.imshow('Object Detection', frame)\n",
    "\n",
    "            # Check for key press to exit\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "# Release video capture device\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# Function to determine direction based on object position\n",
    "def determine_direction(person_x, person_y, object_x, object_y):\n",
    "    if object_x > person_x + 50:\n",
    "        return \"right\"\n",
    "    elif object_x < person_x - 50:\n",
    "        return \"left\"\n",
    "    elif object_y < person_y:\n",
    "        return \"front\"\n",
    "    elif object_y > person_y:\n",
    "        return \"behind\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame, max_distance):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names, positions, and confidences\n",
    "    object_names = []\n",
    "    object_positions = []\n",
    "    confidences = []\n",
    "\n",
    "    # Detect person's position (assumed to be in the center)\n",
    "    person_x, person_y = width // 2, height // 2\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name and position\n",
    "                object_name = classes[class_id]\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                object_names.append(object_name)\n",
    "                object_positions.append((center_x, center_y))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Keep track of detected objects to avoid duplicates\n",
    "    detected_objects = set()\n",
    "\n",
    "    # Iterate through detected objects\n",
    "    for object_name, object_position in zip(object_names, object_positions):\n",
    "        # Check if object has already been detected\n",
    "        if object_name not in detected_objects:\n",
    "            # Calculate distance and direction\n",
    "            object_x, object_y = object_position\n",
    "            distance = calculate_distance(person_x, person_y, object_x, object_y)\n",
    "            direction = determine_direction(person_x, person_y, object_x, object_y)\n",
    "\n",
    "            # Check if object is within max distance\n",
    "            if distance <= max_distance:\n",
    "                # Display information\n",
    "                info_text = f\"{object_name} is {int(distance)} feet away, {direction} of you\"\n",
    "                print(info_text)\n",
    "\n",
    "                # Convert information to speech\n",
    "                engine.say(info_text)\n",
    "                engine.runAndWait()\n",
    "\n",
    "                # Add object to detected set\n",
    "                detected_objects.add(object_name)\n",
    "\n",
    "    # Exit after processing all detected objects\n",
    "    return True\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Busy people walking the city streets in London, HD Stock Footage.mp4\"  # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame with max distance of 10 feet\n",
    "        if detect_objects(frame, max_distance=1000):\n",
    "            # Display the frame\n",
    "            cv2.imshow('Object Detection', frame)\n",
    "\n",
    "            # Check for key press to exit\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "# Release video capture device\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f768ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# Function to determine direction based on object position\n",
    "def determine_direction(person_x, person_y, object_x, object_y):\n",
    "    if object_x > person_x + 50:\n",
    "        return \"right\"\n",
    "    elif object_x < person_x - 50:\n",
    "        return \"left\"\n",
    "    elif object_y < person_y:\n",
    "        return \"front\"\n",
    "    elif object_y > person_y:\n",
    "        return \"behind\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame, max_distance):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Convert frame to blob for YOLO input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass blob through YOLO network\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for object names, positions, and confidences\n",
    "    object_names = []\n",
    "    object_positions = []\n",
    "    confidences = []\n",
    "\n",
    "    # Detect person's position (assumed to be in the center)\n",
    "    person_x, person_y = width // 2, height // 2\n",
    "\n",
    "    # Iterate through each detected object\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out low confidence detections\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, determine its name and position\n",
    "                object_name = classes[class_id]\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                object_names.append(object_name)\n",
    "                object_positions.append((center_x, center_y))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Keep track of detected objects to avoid duplicates\n",
    "    detected_objects = set()\n",
    "\n",
    "    # Iterate through detected objects\n",
    "    for object_name, object_position in zip(object_names, object_positions):\n",
    "        # Check if object has already been detected\n",
    "        if object_name not in detected_objects:\n",
    "            # Calculate distance and direction\n",
    "            object_x, object_y = object_position\n",
    "            distance = calculate_distance(person_x, person_y, object_x, object_y)\n",
    "            direction = determine_direction(person_x, person_y, object_x, object_y)\n",
    "\n",
    "            # Check if object is within max distance\n",
    "            if distance <= max_distance:\n",
    "                # Display information\n",
    "                info_text = f\"{object_name} is {int(distance)} feet away, {direction} of you\"\n",
    "                print(info_text)\n",
    "\n",
    "                # Convert information to speech\n",
    "                engine.say(info_text)\n",
    "                engine.runAndWait()\n",
    "\n",
    "                # Draw bounding box around the object\n",
    "                cv2.rectangle(frame, (object_x - 50, object_y - 50), (object_x + 50, object_y + 50), (0, 255, 0), 2)\n",
    "\n",
    "                # Add object to detected set\n",
    "                detected_objects.add(object_name)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open video capture device\n",
    "video_path = r\"C:\\Users\\MAHESH\\Busy people walking the city streets in London, HD Stock Footage.mp4\"  # Change this to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video capture device is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is successfully read\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame with max distance of 10 feet\n",
    "        detected_frame = detect_objects(frame, max_distance=10)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Object Detection', detected_frame)\n",
    "\n",
    "        # Check for key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release video capture device\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
